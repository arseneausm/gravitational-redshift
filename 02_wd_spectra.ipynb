{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using local paths\n",
      "star and exposure catalogs not found! check paths and run make_catalogs() if you want to use sdss functionality. otherwise ignore.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 16:40:03.770668: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-14 16:40:03.770759: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install galpy if you want to use the gaia module. otherwise, ignore this.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys\n",
    "sys.path.append('../corv/src')\n",
    "sys.path.append('../wdtools')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import corv\n",
    "\n",
    "### Query\n",
    "from astroquery.sdss import SDSS\n",
    "from astroquery.gaia import Gaia\n",
    "from astropy import constants as c\n",
    "import data_selector as ds\n",
    "\n",
    "import wdtools\n",
    "import corv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "d1 = pd.read_csv('data/wd_spectra.csv')\n",
    "d1 = Table.from_pandas(d1)\n",
    "\n",
    "catalog = Table.read('data/00_raw.fits')\n",
    "print(len(catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spAll = Table.read('~/Downloads/spAll-master.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, join_skycoord\n",
    "from astropy import table\n",
    "\n",
    "print(spAll.keys())\n",
    "\n",
    "print(spAll[['RACAT', 'DECCAT']])\n",
    "\n",
    "spAll = spAll[spAll['DECCAT'] < 90]\n",
    "spAll = spAll[spAll['DECCAT'] > -90]\n",
    "\n",
    "catalog['wd_pos'] = SkyCoord(catalog['wd_ra'], catalog['wd_dec'], unit='deg')\n",
    "spAll['wd_pos'] = SkyCoord(spAll['RACAT'], spAll['DECCAT'], unit='deg')\n",
    "\n",
    "join_func = table.join_skycoord(5 * u.arcsecond)\n",
    "sdss5_catalog = table.join(catalog, spAll, join_funcs={'wd_pos': join_skycoord(5 * u.arcsec)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdss5_catalog[['wd_pos_id', 'wd_pos_1', 'wd_pos_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADQL_CODE1 = \"SELECT \\\n",
    "        sdss.original_ext_source_id as bestobjid,\\\n",
    "        gaia_source.source_id\\\n",
    "        FROM gaiaedr3.gaia_source \\\n",
    "        JOIN gaiaedr3.sdssdr13_best_neighbour as sdss\\\n",
    "        ON gaia_source.source_id = sdss.source_id      \\\n",
    "        WHERE gaia_source.source_id IN {}\\\n",
    "    \".format(tuple(catalog['wd_source_id']))\n",
    "\n",
    "job1 = Gaia.launch_job(ADQL_CODE1,dump_to_file=False)\n",
    "d1 = job1.get_results()\n",
    "print(len(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = []\n",
    "bestobjid1 = []\n",
    "\n",
    "for i in tqdm (range(len(catalog))):\n",
    "    notfound = False\n",
    "    a = np.where(d1['source_id'] == catalog['wd_source_id'][i])\n",
    "    \n",
    "    try:\n",
    "        j = a[0][0]\n",
    "    except:\n",
    "        notfound = True\n",
    "        \n",
    "    if not notfound: \n",
    "        try:\n",
    "            bestobjid1.append(d1['bestobjid'][j])\n",
    "        except:\n",
    "            notfound = True\n",
    "    if notfound:\n",
    "        drops.append(i)    \n",
    "        \n",
    "catalog.remove_rows(drops)\n",
    "catalog['wd_bestobjid'] = bestobjid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(catalog['wd_bestobjid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, vstack, hstack\n",
    "\n",
    "stardats = []\n",
    "iters = len(catalog) // 100\n",
    "\n",
    "for i in tqdm(range(iters)):\n",
    "    SDSS_QUERY = \"\"\"select bestObjID, plate, mjd, fiberID\n",
    "        from dbo.SpecObjAll\n",
    "        where bestObjID in {}\"\"\".format(tuple(catalog['wd_bestobjid'][100*i:100*i+100]))\n",
    "    \n",
    "    stardats.append(SDSS.query_sql(SDSS_QUERY))\n",
    "spec = vstack(stardats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = []\n",
    "plate = []\n",
    "mjd = []\n",
    "fiber = []\n",
    "\n",
    "for i in tqdm (range(len(catalog))):\n",
    "    notfound = False\n",
    "    a = np.where(spec['bestObjID'] == catalog['wd_bestobjid'][i])\n",
    "    \n",
    "    try:\n",
    "        j = a[0][0]\n",
    "    except:\n",
    "        notfound = True\n",
    "        \n",
    "    if not notfound: \n",
    "        try:\n",
    "            \n",
    "            plate.append(spec['plate'][j])\n",
    "            mjd.append(spec['mjd'][j])\n",
    "            fiber.append(spec['fiberID'][j])\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            notfound = True\n",
    "    if notfound:\n",
    "        drops.append(i)    \n",
    "        \n",
    "catalog.remove_rows(drops)\n",
    "catalog['plate'] = plate\n",
    "catalog['mjd'] = mjd\n",
    "catalog['fiber'] = fiber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = []\n",
    "wl = []\n",
    "fl = []\n",
    "ivar = []\n",
    "drops = []\n",
    "worked = []\n",
    "\n",
    "for i in tqdm(range(len(catalog))):\n",
    "    try:\n",
    "        spec = SDSS.get_spectra_async(plate=plate[i], fiberID=fiber[i], mjd=mjd[i])[0].get_fits()\n",
    "        \n",
    "        #print(spec[4].header)\n",
    "        \n",
    "        wl.append(10**spec[1].data['loglam'])\n",
    "        fl.append(spec[1].data['flux'])\n",
    "        ivar.append(spec[1].data['ivar'])\n",
    "        worked.append(i)\n",
    "    except:\n",
    "        drops.append(i)\n",
    "        \n",
    "print(len(wl))\n",
    "print(len(fl))\n",
    "print(len(ivar))\n",
    "        \n",
    "catalog.remove_rows(drops)\n",
    "catalog['wd_wl'] = wl\n",
    "catalog['wd_fl'] = fl\n",
    "catalog['wd_ivar'] = ivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(catalog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonormalize(fl, win = 50):\n",
    "    cont_fl = np.repeat(np.nan, len(fl))\n",
    "    \n",
    "    for i in range(len(fl)):\n",
    "        if (i - (win / 2)) < 0:\n",
    "            fl_win = fl[0:(i + (win // 2))]\n",
    "        else:\n",
    "            fl_win = fl[(i - (win // 2)) : (i + (win // 2))]\n",
    "        \n",
    "        cont_fl[i] = np.percentile(fl_win, 90)\n",
    "        \n",
    "    return fl / cont_fl\n",
    "'''\n",
    "def spec_split(bands, wl, fl, window_size = 100):\n",
    "    spec_split = {}\n",
    "    \n",
    "    for i in range(len(bands)):\n",
    "        spec_split[bands.keys()[i]] = np.array([ [wl[\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.plot(catalog['wd_wl'][i], catalog['wd_fl'][i])\n",
    "plt.grid()\n",
    "plt.ylabel(r'Flux [$10^{-17}$ ergs/s/cm2/A]')\n",
    "plt.xlabel(r'Wavelength [A]')\n",
    "plt.title('White Dwarf Spectrum')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i)\n",
    "nwl = catalog['wd_wl'][i]\n",
    "nfl = catalog['wd_fl'][i]\n",
    "cont = pseudonormalize(nfl, 50)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.plot(nwl, cont)\n",
    "plt.grid()\n",
    "plt.ylabel(r'Normalized Flux')\n",
    "plt.xlabel(r'Wavelength [A]')\n",
    "plt.title('Normalized Spectrum')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([np.any(np.isnan(catalog['wd_ivar'][i])) for i in range(len(catalog))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit import Parameters, fit_report, minimize\n",
    "\n",
    "rvs = []\n",
    "e_rvs = []\n",
    "redchi = []\n",
    "drops = []\n",
    "\n",
    "#catalog['wd_ivar'] = [catalog['wd_ivar'][i]  for i in range(len(catalog))]\n",
    "\n",
    "for i in tqdm(range(len(catalog))):\n",
    "    corvmodel = corv.models.make_koester_model(resolution = 1)\n",
    "    param_res, rv_res, rv_init = corv.fit.fit_corv(np.array(catalog['wd_wl'][i]), np.array(catalog['wd_fl'][i]), np.array(catalog['wd_ivar'][i]), corvmodel)\n",
    "    \n",
    "    if rv_res.params['teff'].stderr == None:\n",
    "        rv_res.params['teff'].stderr = 1e-6\n",
    "    if rv_res.params['logg'].stderr == None:\n",
    "        rv_res.params['logg'].stderr = 1e-6\n",
    "    if rv_res.params['RV'].stderr == None:\n",
    "        rv_res.params['RV'].stderr = 1e-6\n",
    "    \n",
    "    f = corv.utils.lineplot(np.array(catalog['wd_wl'][i]), np.array(catalog['wd_fl'][i]), np.array(catalog['wd_ivar'][i]), corvmodel, rv_res.params, gap = 0.3, printparams = True,\n",
    "             figsize = (6, 5))\n",
    "    \n",
    "    f.savefig('spectra/corvfits/corvfit{}.jpg'.format(i))\n",
    "            \n",
    "    rvs.append(rv_res.params['RV'].value)\n",
    "    e_rvs.append(rv_res.params['RV'].stderr)\n",
    "    redchi.append(rv_res.redchi)\n",
    "\n",
    "\n",
    "        \n",
    "#catalog.remove_rows(drops)\n",
    "catalog['rv'] = rvs\n",
    "catalog['e_rv'] = e_rvs\n",
    "catalog['e_rv'][catalog['e_rv'] == None] = 1e-6\n",
    "catalog['rechi'] = redchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(catalog))\n",
    "print(len(rvs))\n",
    "catalog = catalog[catalog['rechi'] < 2.5]\n",
    "catalog = catalog[(catalog['rv'] / catalog['e_rv']) > 5]\n",
    "catalog = catalog[catalog['rv'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['e_rv'].pprint(max_lines=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['e_rv'] = np.array(catalog['e_rv']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,16))\n",
    "\n",
    "\n",
    "has_erv = []\n",
    "for i in range(len(catalog)):\n",
    "    if catalog['e_rv'][i] > 1e-4:\n",
    "        has_erv.append([i, np.mean(catalog['wd_ivar'][i])])\n",
    "        \n",
    "has_erv = np.array(has_erv).T\n",
    "\n",
    "num = np.array([i for i in range(len(catalog))])\n",
    "mean_ivar = np.array([np.mean(catalog['wd_ivar'][i]) for i in range(len(catalog))])\n",
    "\n",
    "'''\n",
    "===============================================\n",
    "                Plot One\n",
    "===============================================\n",
    "'''\n",
    "\n",
    "i = [0,5]\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.scatter(num, mean_ivar, label = 'No Error Reported')\n",
    "plt.scatter(has_erv[0], has_erv[1], label = 'Error Reported')\n",
    "\n",
    "#plt.hlines(1, 0, 40)\n",
    "plt.grid()\n",
    "plt.ylabel(r'Mean ivar')\n",
    "plt.xlabel(r'Spectrum Number')\n",
    "#plt.title('White Dwarf Spectrum')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "\n",
    "plt.scatter(num, mean_ivar, label = 'No Error Reported')\n",
    "plt.scatter(has_erv[0], has_erv[1], label = 'Error Reported')\n",
    "\n",
    "#plt.hlines(1, 0, 40)\n",
    "plt.grid()\n",
    "plt.ylabel(r'Mean ivar')\n",
    "plt.xlabel(r'Spectrum Number')\n",
    "plt.legend()\n",
    "\n",
    "'''\n",
    "===============================================\n",
    "    Plot Two\n",
    "===============================================\n",
    "'''\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "\n",
    "plt.plot(catalog['wd_wl'][i[0]], catalog['wd_fl'][i[0]])\n",
    "plt.text(0.05, 0.14, 'Redchi: {}'.format(round(catalog['rechi'][i[0]], 3)), fontsize=12,\n",
    "                transform = plt.gca().transAxes)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(r'ivar')\n",
    "plt.xlabel(r'Wavelength')\n",
    "plt.title('Spectrum Number {} (No Error Reported)'.format(i[0]))\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "color = plt.cm.coolwarm(catalog['wd_ivar'][i[0]])\n",
    "plt.scatter(catalog['wd_wl'][i[0]], catalog['wd_fl'][i[0]], c=catalog['wd_ivar'][i[0]], cmap = 'coolwarm', s=10)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(r'Flux')\n",
    "plt.xlabel(r'Wavelength')\n",
    "plt.title('Spectrum Number {} (No Error Reported)'.format(i[0]))\n",
    "plt.colorbar(label='ivar')\n",
    "\n",
    "'''\n",
    "===============================================\n",
    "    Plot Three\n",
    "===============================================\n",
    "'''\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "\n",
    "plt.plot(catalog['wd_wl'][i[1]], catalog['wd_fl'][i[1]])\n",
    "plt.text(0.05, 0.14, 'Redchi: {}'.format(round(catalog['rechi'][i[1]], 3)), fontsize=12,\n",
    "                transform = plt.gca().transAxes)\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(r'ivar')\n",
    "plt.xlabel(r'Wavelength')\n",
    "plt.title('Spectrum Number {} (Error Reported)'.format(i[1]))\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "#color = plt.cm.coolwarm(catalog['wd_ivar'][i])\n",
    "plt.scatter(catalog['wd_wl'][i[1]], catalog['wd_fl'][i[1]], c=catalog['wd_ivar'][i[1]], cmap = 'coolwarm', s=10)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(r'Flux')\n",
    "plt.xlabel(r'Wavelength')\n",
    "plt.title('Spectrum Number {} (Error Reported)'.format(i[1]))\n",
    "plt.legend()\n",
    "plt.colorbar(label='ivar')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(catalog[['rv','e_rv']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 9))\n",
    "#axes.grid()\n",
    "axes.hist(catalog['ms_rv'], bins = 15, alpha=0.5, color='black', label='Main sequence')\n",
    "#axes.hist(catalog['rv'], bins = 15, alpha=0.5, color='red', label='White dwarf')\n",
    "ymin, ymax = axes.get_ylim()\n",
    "axes.vlines(np.mean(catalog['ms_rv']), ymin, ymax, linestyles='dashed')\n",
    "#axes.vlines(np.mean(catalog['rv']), ymin, ymax, linestyles='dashed', color='red')\n",
    "\n",
    "#axes[0].set_title('Gravitational Redshift', fontsize=20)\n",
    "axes.set_xlabel(r'$RV [km/s]$', fontsize=18)\n",
    "axes.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog['g_redshift'] = catalog['rv'] - catalog['ms_rv']\n",
    "catalog['eg_redshift'] = catalog['ms_erv'] + catalog['e_rv']\n",
    "\n",
    "#catalog = catalog[catalog['g_redshift'] > -100]\n",
    "#catalog = catalog[catalog['g_redshift'] < 100]\n",
    "\n",
    "print(np.mean(catalog['g_redshift']))\n",
    "print(len(catalog))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.grid()\n",
    "plt.hist(catalog['g_redshift'], bins = 20, histtype='step', color='black')\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(np.mean(catalog['g_redshift']), ymin, ymax, linestyles='dashed')\n",
    "plt.title('Gravitational Redshift', fontsize=20)\n",
    "plt.xlabel(r'$RV_{MS} - RV_{WD}$', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in catalog.columns:\n",
    "    if catalog[col].dtype == object: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.remove_columns(['wd_wl', 'wd_fl', 'wd_ivar'])\n",
    "\n",
    "catalog.write('data/02_wd_rvs.fits', format='fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
